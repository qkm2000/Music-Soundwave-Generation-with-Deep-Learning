{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n",
    "\n",
    "this notebook is built to classify all the images in landscape1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports\n",
    "\n",
    "this section imports all relevant libraries, the CLIP model, and the earcon tags from the earcon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in earcon dataset\n",
    "import os\n",
    "\n",
    "if os.path.isfile(\"../dataset/earcon_dataset/earcon_dataset.xlsx\"):\n",
    "    earcon_dataset = pd.read_excel('../dataset/earcon_dataset/earcon_dataset.xlsx')\n",
    "\n",
    "earcon_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earcon_tags = earcon_dataset['tags'].tolist()\n",
    "\n",
    "taglist = []\n",
    "for element in earcon_tags:\n",
    "    temp = element.replace(\"[\", \"\")\n",
    "    temp = temp.replace(\"]\", \"\")\n",
    "    temp = temp.replace(\"'\", \"\")\n",
    "    temp = temp.split(\", \")\n",
    "    # print(temp)\n",
    "    for tag in temp:\n",
    "        tag = tag.strip()\n",
    "        tag = tag.lower()\n",
    "        if tag not in taglist:\n",
    "            taglist.append(tag)\n",
    "\n",
    "print(f\"There are {len(taglist)} unique tags in the dataset\")\n",
    "print(f\"Here are the first 10 tags: {taglist[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load paths\n",
    "\n",
    "this section crawls all the images so that we have a list of image files that we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the code using validation coast from landscape dataset 1\n",
    "\n",
    "sub_folders = [\n",
    "    \"Coast\",\n",
    "    \"Desert\",\n",
    "    \"Forest\",\n",
    "    \"Glacier\",\n",
    "    \"Mountain\"\n",
    "]\n",
    "\n",
    "split = [\n",
    "    \"test\",\n",
    "    \"train\",\n",
    "    \"validation\"\n",
    "]\n",
    "\n",
    "folders = [\n",
    "    \"../dataset/landscape1/Testing Data/\",\n",
    "    \"../dataset/landscape1/Training Data/\",\n",
    "    \"../dataset/landscape1/Validation Data/\",\n",
    "]\n",
    "\n",
    "image_paths = []\n",
    "\n",
    "# for filepath in folders:\n",
    "for i in range(len(folders)):\n",
    "    for folder in sub_folders:\n",
    "        for item in os.scandir(folders[i] + folder):\n",
    "            image_paths.append({\"split\": split[i], \"folder\": folder, \"filename\": item.name, \"filepath\": item.path})\n",
    "\n",
    "image_paths = pd.DataFrame(image_paths)\n",
    "image_paths.to_csv(\"../dataset/landscape1/csvs/image_paths.csv\", index=False)\n",
    "image_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the tags\n",
    "text_tokens = clip.tokenize(taglist).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the image classification results\n",
    "image_classification = []\n",
    "\n",
    "splits = image_paths[\"split\"].tolist()\n",
    "folders = image_paths[\"folder\"].tolist()\n",
    "filenames = image_paths[\"filename\"].tolist()\n",
    "paths = image_paths[\"filepath\"].tolist()\n",
    "\n",
    "# Forward pass for each image\n",
    "for i in range(len(paths)):\n",
    "    # Load and preprocess the image\n",
    "    image = preprocess(Image.open(paths[i])).unsqueeze(0).to(device)\n",
    "\n",
    "    # Forward pass to get image and text features\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(text_tokens)\n",
    "\n",
    "    # Normalize features to compare cosine similarity\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Compute similarity between the image and text prompts\n",
    "    similarities = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "    # Get the top 100 predictions (tags and similarity scores)\n",
    "    top_preds = torch.topk(similarities, 100)\n",
    "    top_indices = top_preds.indices.squeeze(0).tolist()\n",
    "    top_scores = top_preds.values.squeeze(0).tolist()\n",
    "\n",
    "    # Create a dictionary entry for the image classification\n",
    "    image_classification.append({\n",
    "        \"split\": splits[i],\n",
    "        \"folder\": folders[i],\n",
    "        \"filename\": filenames[i],\n",
    "        \"image_path\": paths[i],\n",
    "        \"top_tags\": [taglist[i] for i in top_indices],\n",
    "        \"similarity_scores\": top_scores\n",
    "    })\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"Processed {i+1}/{len(paths)} images\")\n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame\n",
    "df = pd.DataFrame(image_classification)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"../dataset/landscape1/csvs/image_classification.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
